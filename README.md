# ML-training-model-projects

# Machine Learning Model Training Projects

Welcome to this repository, which contains two machine learning projects demonstrating model training for **supervised learning** tasks:
1. **Classification** (Titanic Survival Prediction)
2. **Regression** (Calories Burnt Prediction)

## ğŸš€ Projects Overview

### **Project 1: Titanic Survival Prediction** ğŸ›³ï¸ [here is the app link](https://titanic-aryx.streamlit.app/)
- **Objective**: Predict passenger survivability on the Titanic using machine learning.
- **Algorithm Used**: Logistic Regression
- **Type**: Supervised Classification
- **Dataset**: [Titanic Dataset](https://www.kaggle.com/c/titanic)

#### **Steps Involved**:
1. Data Preprocessing (Handling missing values, encoding categorical variables, feature selection)
2. Exploratory Data Analysis (EDA)
3. Model Training using **Logistic Regression**
4. Model Evaluation using Accuracy Score

ğŸ“Œ **Key Outcome**: A classification model that predicts whether a passenger survived based on available features.

---

### **Project 2: Calories Burnt Prediction** ğŸ”¥
- **Objective**: Predict the number of calories burnt based on various factors.
- **Algorithm Used**: XGBoost Regressor
- **Type**: Supervised Regression
- **Dataset**: [Calories Burnt Dataset](https://www.kaggle.com/datasets/fmendes/fmendesdat263xdemos)

#### **Steps Involved**:
1. Data Cleaning and Preprocessing
2. Feature Engineering
3. Model Training using **XGBoost Regressor**
4. Model Performance Evaluation (RMSE, RÂ² Score)

ğŸ“Œ **Key Outcome**: A regression model that predicts the calories burnt based on input features.

---


## ğŸ“Œ Dependencies
- Python 3.x
- Pandas
- NumPy
- Matplotlib
- Seaborn
- Scikit-learn
- XGBoost
- Jupyter Notebook



